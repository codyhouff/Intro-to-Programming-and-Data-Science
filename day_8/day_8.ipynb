{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using APIs to Get Data From the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**API** means Application Programmer Interface\n",
    "\n",
    "An API is a set of instructions that describe how computers can interact with each other to request and receive information.\n",
    "\n",
    "Some important questions we will ask that help us discover APIs is below.\n",
    "\n",
    "|Question | In technical terms |\n",
    "|:---------|:--------------------|\n",
    "|Where is my data? | What is the domain? |\n",
    "|How do I learn what data is available?| Where is the documentation? |\n",
    "|How do I request specific data?| How do I formulate a URL for a specific purpose? |\n",
    "|How do I interpret the data?| What is the structure and format of the output?|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's walk through an example in the browser**\n",
    "\n",
    "PlaceKitten!\n",
    "\n",
    "In a browser, go to http://www.placekitten.com\n",
    "\n",
    "|In technical terms | PlaceKitten |\n",
    "|:---------|:--------------------|\n",
    "|What is the domain? | http://www.placekitten.com |\n",
    "|Where is the documentation?| The documentation is on the home page. |\n",
    "|How do I formulate a URL for a specific purpose? | You put it in the url like http://www.placekitten/width/height |\n",
    "|What is the structure and format of the output?| It's an image! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing placekitten in python\n",
    "\n",
    "We're going to use a special library called <code>requests</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image  # This line lets you display images. We'll use that in a bit.\n",
    "\n",
    "# This line lets you use python to download data from the web.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a 200 by 300 image from placekitten.\n",
    "r = requests.get('http://www.placekitten.com/200/300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the status code\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the content\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image function to display the image\n",
    "display(Image(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a function that takes in the width and height and prints an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Can you write a loop to show several images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a loop that shows multiple images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Getting World Times\n",
    "\n",
    "This example introduces a slightly more complicated API. It also introduces **JSON** which is a very common data format.\n",
    "\n",
    "The API (including some documentation) is at http://worldtimeapi.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download list of time zones\n",
    "r = requests.get(\"http://worldtimeapi.org/api/timezone\")\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Use the .json() function to get the response converted to a dictionary or list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .json() function to get the response converted to a dictionary or list\n",
    "# What did it return?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Get the time for your time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Get the time for your IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time for your IP address\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Getting Wikipedia pages\n",
    "\n",
    "Wikipedia also has an open API, and I want to use it to show one other tip for using the `requests` library; many APIs will take in a set of parameters, which you can pass as a parameter dictionary.\n",
    "\n",
    "The documentation for the very extensive API is [here](https://www.mediawiki.org/wiki/API:Main_page). Many of the operations require you to authenticate (which we will cover next), but some things, like getting the content of a page, do not.\n",
    "\n",
    "For example, the following code gets the recent changes to Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "endpt = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "\n",
    "def get_last_pages_changed(n):\n",
    "    params = {'action': 'query',\n",
    "          'format': 'json',\n",
    "          'list': 'recentchanges',\n",
    "          'rcnamespace': '0',\n",
    "          'rclimit': n}\n",
    "    r = requests.get(endpt, params=params)\n",
    "    #print(r.json())\n",
    "    #print(r.json()['query']['recentchanges'])\n",
    "    result = []\n",
    "    content = r.json()['query']['recentchanges']\n",
    "    for page in content:\n",
    "        result.append(page['title'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_last_pages_changed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Review the documentation (and Google) to see if you can figure out how to get a list of all of the users who have ever edited the most recently edited Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Intro to Twitter API\n",
    "\n",
    "In order to use the Twitter API, you need to do two things:\n",
    "\n",
    "1. Install tweepy. This is a python library designed to make it easier to use the API (rather than using `requests` directly. I made [this video](https://www.youtube.com/watch?v=TASX3evcgG4) to walk you through how to install tweepy in Anaconda.\n",
    "\n",
    "2. To use the Twitter API, you need to be authenticated, and so you need a developer account. [This page](https://wiki.communitydata.science/Intro_to_Programming_and_Data_Science_(Summer_2020)/Twitter_authentication_setup) explains how to get a developer account.\n",
    "\n",
    "Once you have your keys, you should create a file called `twitter_authentication.py` in the same directory as this file. It should contain the following four lines (replace the fake strings below with the corresponding keys from your twitter account):\n",
    "\n",
    "```\n",
    "CONSUMER_KEY = 'zFxMGdKmbo4e72X8Fi2FYr54v'\n",
    "CONSUMER_SECRET = 'SetuIC9x6zPQXPZrc9cKTph7AMSngUZSf745GXT0QZTrnWeELQ'\n",
    "ACCESS_TOKEN = '16614440-V09URsqNfP0V0JYZCD65NhpJAcPZ6Wb9A5ar9JrUT'\n",
    "ACCESS_TOKEN_SECRET = 'oxVSzC1OjXOVVYrBvGyy6XKKe772Jdvvw6Opb3bSLdIb'\n",
    "```\n",
    "\n",
    "Note that the consumer key and consumer secret are called API key and API secret in the new Twitter interface.\n",
    "\n",
    "In general, it is a good practice to keep your keys (which should be secret) separate from your code, which you can share. In this case, we put them in a different file and then import them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads the tweepy library and imports these keys from the `twitter_authentication.py` file, and then prepares to \"log in\" to your account for the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "from twitter_authentication import CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# We then create an api object, based on the auth object created with your credentials\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limiting\n",
    "\n",
    "You will quickly learn that the Twitter API is \"rate limited\". This means that they will only let each account make a certain number of calls to their API in a given time period. The default rate is quite low - many calls only allow 15 calls per 15 minutes.\n",
    "\n",
    "You may notice above that we had the code:\n",
    "```\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "```\n",
    "the `wait_on_rate_limit=True` tells your code to wait for 15 minutes if it gets back a message that you've exceeded a rate limit. This can get annoying when debugging, so be careful with how often you try things - sometimes it makes sense, for example, to try to get a small amount of data that only takes one call and make sure that your code works before trying to get all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline\n",
    "\n",
    "This first example is just to make sure it's working. It should print out the last 100 tweets from your timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the last 100 tweets\n",
    "public_tweets = api.home_timeline(count=100)\n",
    "\n",
    "# And print the text from them\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these `tweet` objects contains lots of additional information. This shows all of the metadata available for the last one we looked at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to change the `count` argument above, and you'll quickly learn that if you raise it over 200, you will still only get 200 tweets. If you want to print more than 200 tweets, you may need to use a [cursor](http://docs.tweepy.org/en/v3.5.0/cursor_tutorial.html).\n",
    "\n",
    "This is basically tweepy's clever way of breaking what you want to do into multiple calls to the API.\n",
    "\n",
    "For example, this call will get 350 tweets. The `count` argument (optional) says how many tweets to get per call, and the argument in `.items()` is how many to get in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.home_timeline, count = 175).items(350):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Followers\n",
    "\n",
    "You can also get information about a user, such as who their followers are.\n",
    "\n",
    "Here's information about me and some of my followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user('jdfoote')\n",
    "\n",
    "print(user.screen_name + \" has \" + str(user.followers_count) + \" followers.\")\n",
    "\n",
    "print(\"They include these 100 people:\")\n",
    "\n",
    "for follower in user.followers(count=100):\n",
    "    print(follower.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what that user object looks like for my user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the user object for one of my followers, which is nearly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 200 is the maximum number of followers that you can get at one time. If you want to get information about all of a user's followers, you will need to use a cursor. If you are getting many followers, you will almost certainly hit rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for follower in tweepy.Cursor(api.followers, screen_name='jdfoote', count=200).items():\n",
    "    #print(follower.screen_name)\n",
    "    f.append(follower.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n",
    "\n",
    "For most of your research, you may be interested in how people are talking about a given topic. There are two main ways to do this.\n",
    "\n",
    "The first is the search API ([Official Twitter info on the Search API](https://developer.twitter.com/en/docs/tweets/search/overview)). We only have access to \"[Standard Search](https://developer.twitter.com/en/docs/tweets/search/overview/standard)\", the most limited of Twitter Search API options, which is limited to the last 7 days.\n",
    "\n",
    "\n",
    "**Note that if you would like to use Twitter for a project or a paper, you can request access to the Academic Research API, which includes historical search and a much higher limit on the number of tweets you can request**\n",
    "\n",
    "Unforutnately, tweepy doesn't yet support the v2 API for Twitter, but [here is an example of how to use it](https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/master/Full-Archive-Search/full-archive-search.py) with just requests.\n",
    "\n",
    "\n",
    "[This page](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets) is the documentation for Standard Search and has some helpful intel about modifying the parameters.\n",
    "\n",
    "Below is a simple example that gets the last 20 tweets about data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.search('\"from:@jdfoote\"', count=20)\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.user.screen_name + \"\\t\" + str(tweet.created_at) + \"\\t\" + tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many of these results are truncated. If you want the full tweet, you actually have to modify the call a little bit, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.search('\"data science\"', count=20, tweet_mode='extended')\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.user.screen_name + \"\\t\" + str(tweet.created_at) + \"\\t\" + tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Search resources\n",
    "\n",
    "* [Tweepy extended tweets documentation](http://docs.tweepy.org/en/latest/extended_tweets.html)\n",
    "* [Twitter documentation for crafting queries](https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators). This includes things like how to search by geography or remove retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "The other option is to \"stream\" tweets. Instead of looking backward, this just keeps you connected to Twitter and whenever new tweets come in, they are sent to your program. You would typicaly just keep the program running and keep writing the data that you want to an external file.\n",
    "\n",
    "As with the search API, there are some caveats. One is that (I believe) there is no guarantee that this is all of the tweets that match. If you try to filter by very popular terms, then Twitter may give you only a sample of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, tweet):\n",
    "        print(tweet.author.screen_name + \"\\t\" + tweet.text)\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print( 'Error: ' + repr(status_code))\n",
    "        return False\n",
    "\n",
    "l = StreamListener()\n",
    "streamer = tweepy.Stream(auth=auth, listener=l, tweet_mode='extended')\n",
    "\n",
    "keywords = ['Purdue', '\"data science\"']\n",
    "streamer.filter(track = keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "\n",
    "7. Use the streaming API to produce a list of 1000 tweets about a topic.\n",
    "2. From that list of 1000 tweets, eliminate retweets.\n",
    "4. For each original tweet, create a dictionary with the number of times you see it retweeted in your dataset.\n",
    "5. Get a list of the URLs in your dataset\n",
    "3. Now, see if you can figure out how to eliminate retweets in the query instead.\n",
    "7. Get the last 50 tweets from West Lafayette, using the search API. (Hint - look up the geocode information [here](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)).\n",
    "8. Alter the streaming algorithm to include a \"locations\" filter to get tweets from New York City. You need to use the order sw_lng, sw_lat, ne_lng, ne_lat for the four coordinates instead of a radius as in the search API.\n",
    "\n",
    "### BONUS Questions\n",
    "1. For each of your followers, get *their* followers (investigate time.sleep to throttle your computation)\n",
    "2. Identify the follower you have that also follows the most of your followers.\n",
    "3. How many users follow you but none of your followers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
